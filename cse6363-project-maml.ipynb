{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 6363 Project for Model Agnostic Meta Learning (MAML)\n",
    "Daylen Griffen\n",
    "Austin Johnson\n",
    "Bailey Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Training Code (Single Task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "# Transform for the dataset\n",
    "transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Load datasets (we'll use a small subset for demonstration)\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Filter to get only cats (3) and dogs (5)\n",
    "train_data.targets = [target for target in train_data.targets if target in [3, 5]]\n",
    "train_data.data = train_data.data[train_data.targets]\n",
    "\n",
    "test_data.targets = [target for target in test_data.targets if target in [3, 5]]\n",
    "test_data.data = test_data.data[test_data.targets]\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define model (using a pre-trained ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Output layer for cat and dog\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop (normal training)\n",
    "def train_normal():\n",
    "    model.train()\n",
    "    for epoch in range(5):  # Train for 5 epochs\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate\n",
    "def evaluate_normal():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Train and evaluate normal model\n",
    "train_normal()\n",
    "evaluate_normal()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAML Training Code (Meta-Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from higher import innerloop_ctx\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "\n",
    "# Same transformation as before\n",
    "transform = transforms.Compose([transforms.Resize((128, 128)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Load datasets for two categories (Cats vs Dogs)\n",
    "train_data = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_data.targets = [target for target in train_data.targets if target in [3, 5]]\n",
    "train_data.data = train_data.data[train_data.targets]\n",
    "\n",
    "test_data.targets = [target for target in test_data.targets if target in [3, 5]]\n",
    "test_data.data = test_data.data[test_data.targets]\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Define the model (ResNet18)\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)  # Output layer for 2 classes: cat and dog\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Meta-learning parameters\n",
    "meta_optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "meta_batch_size = 4  # Number of tasks in each batch\n",
    "\n",
    "# MAML inner loop (task-specific adaptation)\n",
    "def inner_loop(model, task_data, criterion, learning_rate=0.01):\n",
    "    task_model = model\n",
    "    optimizer = optim.SGD(task_model.parameters(), lr=learning_rate)\n",
    "    inputs, labels = task_data\n",
    "    optimizer.zero_grad()\n",
    "    outputs = task_model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return task_model, loss\n",
    "\n",
    "# MAML meta-training loop\n",
    "def train_maml():\n",
    "    model.train()\n",
    "    for epoch in range(5):  # Train for 5 epochs\n",
    "        meta_loss = 0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            # Create task-specific data (for simplicity we use the same task)\n",
    "            task_data = (inputs, labels)\n",
    "\n",
    "            # Perform MAML inner loop (adaptation on the task)\n",
    "            task_model = model\n",
    "            task_model, loss = inner_loop(task_model, task_data, criterion)\n",
    "\n",
    "            # Meta-objective (outer loop)\n",
    "            meta_loss += loss\n",
    "\n",
    "        # Update meta-model (outer loop)\n",
    "        meta_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        meta_optimizer.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/5], Meta Loss: {meta_loss.item()}\")\n",
    "\n",
    "# Evaluate MAML model\n",
    "def evaluate_maml():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy: {accuracy}%\")\n",
    "\n",
    "# Train and evaluate using MAML\n",
    "train_maml()\n",
    "evaluate_maml()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison:\n",
    "1. Normal Training:\n",
    "The model learns only for the specific task of classifying cats vs dogs.\n",
    "The training process uses a larger dataset, and the model learns specific features for this dataset.\n",
    "We train the model for 5 epochs, with the optimizer gradually adjusting the weights based on the loss calculated from the entire dataset.  \n",
    "\n",
    "2. MAML Training:\n",
    "In MAML, the model is trained over multiple tasks (even though in this simple example we have just one task: cats vs dogs).\n",
    "The model adapts quickly by fine-tuning its parameters for each task using a few gradient steps in the inner loop.\n",
    "The outer loop updates the model's parameters to make it easier for the model to adapt to new tasks in the future.  \n",
    "\n",
    "Results:\n",
    "Without MAML: The model will train for 5 epochs and show an accuracy on the test set based on the single task (cats vs dogs).  \n",
    "\n",
    "With MAML: The model will also train for 5 epochs but will have the ability to adapt quickly to new tasks with minimal data, as it learns a good initialization during meta-training.  \n",
    "\n",
    "In practice, the performance difference between normal training and MAML becomes more evident when you introduce tasks with limited data. MAML is designed to excel in few-shot learning situations where the model needs to adapt quickly to new tasks with very few examples."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
